{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics Basics\n",
        "\n",
        "Q1 What is statistics, and why is it important ?\n",
        "\n",
        "Statistics is a branch of mathematics focused on collecting, analyzing, interpreting, presenting, and organizing data. Essentially, it's the science of making sense of data by identifying patterns, trends, and relationships.\n",
        "\n",
        " Why is statistics important?\n",
        "\n",
        "1. **Informed Decision-Making**: Statistics provides the tools to make sound decisions based on data, whether in business, healthcare, or policy-making.\n",
        "   \n",
        "2. **Prediction and Forecasting**: From weather predictions to stock market trends, statistics helps forecast future outcomes using past data.\n",
        "\n",
        "3. **Research and Innovation**: It's the backbone of scientific research, enabling researchers to test hypotheses, validate results, and draw meaningful conclusions.\n",
        "\n",
        "4. **Quality Control**: Industries rely on statistics to maintain product quality and improve processes.\n",
        "\n",
        "5. **Everyday Applications**: Even in daily life, statistics help us understand probabilities, like the chances of rain or success in certain activities.\n",
        "\n",
        "\n",
        "Q2 What are the two main types of statistics ?\n",
        "\n",
        "The two main types of statistics are:\n",
        "\n",
        "1. **Descriptive Statistics**:  \n",
        "   - These summarize and describe the main features of a dataset.  \n",
        "   - Common methods include measures like mean, median, mode, range, variance, and standard deviation.  \n",
        "   - Tools like graphs, charts, and tables fall under this type to visually represent data.\n",
        "\n",
        "2. **Inferential Statistics**:  \n",
        "   - These are used to make predictions or generalizations about a population based on a sample.  \n",
        "   - Techniques include hypothesis testing, confidence intervals, and regression analysis.  \n",
        "   - It involves drawing conclusions and making decisions under uncertainty.\n",
        "\n",
        "Q3 What are descriptive statistics ?\n",
        "\n",
        "Descriptive statistics involve methods for summarizing and organizing data so that it can be easily understood and interpreted. These statistics provide a clear snapshot of the main characteristics of a dataset without making predictions or inferences.\n",
        "\n",
        "1. **Central Tendency Measures**:\n",
        "   - Mean (average)\n",
        "   - Median (middle value)\n",
        "   - Mode (most frequent value)\n",
        "\n",
        "2. **Dispersion Measures**:\n",
        "   - Range (difference between highest and lowest values)\n",
        "   - Variance (spread of the data)\n",
        "   - Standard Deviation (how much data deviates from the mean)\n",
        "\n",
        "3. **Visualization Tools**:\n",
        "   - Graphs (e.g., bar graphs, pie charts)\n",
        "   - Tables (e.g., frequency distribution)\n",
        "   - Charts (e.g., histograms)\n",
        "\n",
        "Q4 What is inferential statistics ?\n",
        "\n",
        "Inferential statistics is a branch of statistics that allows us to make predictions, generalizations, or conclusions about a population based on a smaller sample of data. It goes beyond merely describing the data and helps us infer patterns or make decisions under conditions of uncertainty.\n",
        "\n",
        "Key Aspects of Inferential Statistics:\n",
        "\n",
        "1. **Sampling**: Instead of studying an entire population (which is often impractical), inferential statistics relies on analyzing a representative sample.\n",
        "\n",
        "2. **Hypothesis Testing**:\n",
        "   - Formulating and testing assumptions (hypotheses) about the population.\n",
        "   - Determining whether observed patterns in data are statistically significant.\n",
        "\n",
        "3. **Confidence Intervals**: Providing an estimated range of values within which the true population parameter is likely to fall, with a certain level of confidence (e.g., 95%).\n",
        "\n",
        "4. **Prediction Models**: Techniques like regression analysis to predict future trends or relationships between variables.\n",
        "\n",
        "Q5 What is sampling in statistics ?\n",
        "\n",
        "Sampling in statistics refers to the process of selecting a subset (sample) of individuals, items, or data points from a larger population to analyze and draw conclusions about the entire population. Since studying an entire population is often impractical or impossible, sampling makes it feasible to study and understand patterns, trends, and characteristics efficiently.\n",
        "\n",
        "Types of Sampling:\n",
        "\n",
        "1. **Random Sampling**: Every individual in the population has an equal chance of being selected.\n",
        "2. **Stratified Sampling**: The population is divided into groups (strata) based on shared characteristics, and samples are taken from each group.\n",
        "3. **Systematic Sampling**: Items are selected at regular intervals from an ordered population list.\n",
        "4. **Cluster Sampling**: The population is divided into clusters, and a sample of clusters is chosen for analysis.\n",
        "5. **Convenience Sampling**: Samples are selected based on ease of access, though this can lead to biased results.\n",
        "\n",
        "Q6 What are the different types of sampling methods ?\n",
        "\n",
        "Sampling methods are strategies used to select a portion of a population for analysis. Different methods ensure that the sample accurately represents the population or meets specific study requirements. Here are the key types:\n",
        "\n",
        " 1. **Probability Sampling** (Every individual has a chance of being selected):\n",
        "   - **Simple Random Sampling**: Every member of the population has an equal chance of selection, often using random number generators.\n",
        "   - **Stratified Sampling**: The population is divided into distinct groups (strata), and samples are taken proportionally from each.\n",
        "   - **Systematic Sampling**: Members are selected at regular intervals from an ordered population list.\n",
        "   - **Cluster Sampling**: The population is divided into clusters, and specific clusters are randomly selected for study.\n",
        "\n",
        "2. **Non-Probability Sampling** (Not everyone has a chance of being selected):\n",
        "   - **Convenience Sampling**: Selection based on ease of access (e.g., surveying people nearby).\n",
        "   - **Judgmental/Purposive Sampling**: Individuals are chosen based on the researcher’s judgment about their suitability.\n",
        "   - **Quota Sampling**: Samples are chosen to meet predefined quotas for specific groups.\n",
        "   - **Snowball Sampling**: Current participants recruit others, often used for hard-to-reach populations.\n",
        "\n",
        "Q7  What is the difference between random and non-random sampling\n",
        "\n",
        "The primary difference between random and non-random sampling lies in how samples are selected and the level of bias involved in the process.\n",
        "\n",
        "**Random Sampling**:\n",
        "\n",
        "- **Definition**: Every individual in the population has an equal chance of being selected. This selection is made through random processes, such as lottery draws or random number generators.\n",
        "- **Features**:\n",
        "  - Minimizes bias.\n",
        "  - Results are more likely to represent the population accurately.\n",
        "  - Examples: Simple Random Sampling, Stratified Sampling, Cluster Sampling.\n",
        "- **Use Case**: Ideal for studies where accuracy and generalizability to the population are critical.\n",
        "\n",
        " **Non-Random Sampling**:\n",
        "\n",
        "- **Definition**: Samples are selected based on specific criteria or convenience rather than randomization, meaning not all individuals have a chance of being included.\n",
        "- **Features**:\n",
        "  - Can introduce bias, affecting the reliability of the findings.\n",
        "  - Often faster and easier to implement but may lack population representativeness.\n",
        "  - Examples: Convenience Sampling, Purposive Sampling, Snowball Sampling.\n",
        "- **Use Case**: Suitable for exploratory studies or when resources and time are limited.\n",
        "\n",
        "\n",
        "Q8 Define and give examples of qualitative and quantitative data ?\n",
        "\n",
        " Qualitative Data:\n",
        "\n",
        "- **Definition**: Non-numerical data that describes qualities, characteristics, or categories. It provides descriptive insights and is often subjective.\n",
        "\n",
        "- **Examples**:\n",
        "\n",
        "  - Hair colors of individuals (e.g., black, brown, blonde).\n",
        "  - Types of cuisine (e.g., Indian, Italian, Chinese).\n",
        "  - Customer feedback (e.g., \"excellent,\" \"average,\" \"poor\").\n",
        "  - Marital status (e.g., single, married, divorced).\n",
        "\n",
        " Quantitative Data:\n",
        "\n",
        "- **Definition**: Numerical data that represents quantities, amounts, or measurements. It can be analyzed mathematically.\n",
        "- **Examples**:\n",
        "\n",
        "  - Heights of people (e.g., 150 cm, 165 cm, 180 cm).\n",
        "  - Test scores (e.g., 85, 90, 72).\n",
        "  - Daily temperature readings (e.g., 25°C, 30°C, 35°C).\n",
        "  - Number of employees in a company (e.g., 50, 200, 1,000).\n",
        "\n",
        "Q9 What are the different types of data in statistics ?\n",
        "\n",
        "In statistics, data is broadly categorized into **qualitative** (categorical) and **quantitative** (numerical) types. These are further divided into subtypes:\n",
        "\n",
        "1. **Qualitative Data** (Categorical):\n",
        "   - **Nominal Data**: Labels or categories without a specific order.  \n",
        "     *Examples*: Gender (male/female), Blood type (A, B, O), Eye color (blue, green, brown).  \n",
        "   - **Ordinal Data**: Categories with a meaningful order but no fixed interval between values.  \n",
        "     *Examples*: Customer satisfaction levels (poor, fair, excellent), Education level (high school, undergraduate, postgraduate).\n",
        "\n",
        " 2. **Quantitative Data** (Numerical):\n",
        "   - **Discrete Data**: Whole numbers, often counts or items that can’t be divided.  \n",
        "     *Examples*: Number of students in a class, Cars in a parking lot, Goals scored in a match.  \n",
        "   - **Continuous Data**: Measurable quantities that can take any value within a range.  \n",
        "     *Examples*: Height (5.8 ft), Weight (68.5 kg), Temperature (36.7°C).\n",
        "\n",
        "Q10 Explain nominal, ordinal, interval, and ratio levels of measurement ?\n",
        "\n",
        "The levels of measurement are classifications used in statistics to describe the nature of data. These levels help determine the appropriate statistical techniques for analysis. Here’s an explanation of each:\n",
        "\n",
        "1. **Nominal Level**:\n",
        "   - **Definition**: Data that consists of labels or categories without a specific order. It’s used to classify or group data.\n",
        "   - **Characteristics**:\n",
        "     - No meaningful rank or order.\n",
        "     - Cannot perform mathematical operations.\n",
        "   - **Examples**:\n",
        "     - Gender (male, female, non-binary).\n",
        "     - Eye colors (blue, green, brown).\n",
        "     - Types of fruits (apple, orange, banana).\n",
        "\n",
        "2. **Ordinal Level**:\n",
        "   - **Definition**: Data with categories that have a meaningful order or ranking, but the intervals between ranks are not equal or measurable.\n",
        "   - **Characteristics**:\n",
        "     - Represents relative positioning.\n",
        "     - Differences between ranks are undefined.\n",
        "   - **Examples**:\n",
        "     - Customer satisfaction levels (poor, fair, good, excellent).\n",
        "     - Education levels (high school, undergraduate, postgraduate).\n",
        "     - Race standings (1st, 2nd, 3rd).\n",
        "\n",
        " 3. **Interval Level**:\n",
        "   - **Definition**: Data with ordered values where the intervals between values are meaningful, but there is no true zero point.\n",
        "   - **Characteristics**:\n",
        "     - Allows addition and subtraction.\n",
        "     - Ratios (e.g., twice or half) are not meaningful.\n",
        "   - **Examples**:\n",
        "     - Temperature in Celsius or Fahrenheit (e.g., 20°C, 30°C).\n",
        "     - Time of day on a 12-hour clock.\n",
        "     - IQ scores.\n",
        "\n",
        "4. **Ratio Level**:\n",
        "   - **Definition**: Data with ordered values, equal intervals, and a true zero point, allowing for meaningful ratios.\n",
        "   - **Characteristics**:\n",
        "     - All arithmetic operations (e.g., addition, subtraction, multiplication, division) are valid.\n",
        "     - Has a clear “absence” of the measured attribute at zero.\n",
        "   - **Examples**:\n",
        "     - Height (e.g., 150 cm, 170 cm).\n",
        "     - Weight (e.g., 60 kg, 80 kg).\n",
        "     - Income (e.g., $0, $50,000).\n",
        "\n",
        "Q11  What is the measure of central tendency ?\n",
        "\n",
        "The measure of central tendency refers to statistical metrics used to identify the central or typical value in a dataset. These measures help summarize the dataset and provide insights into its central characteristics.\n",
        "\n",
        "Key Measures of Central Tendency:\n",
        "\n",
        "1. **Mean** (Average):\n",
        "   - Calculated by summing all data values and dividing by the number of values.\n",
        "   - *Example*: The mean of 10, 20, 30 is \\((10+20+30)/3 = 20\\).\n",
        "\n",
        "2. **Median**:\n",
        "   - The middle value when data is arranged in ascending or descending order.\n",
        "   - *Example*: For the dataset \\[10, 20, 30\\], the median is 20. If there’s an even number of data points, it’s the average of the two middle values.\n",
        "\n",
        "3. **Mode**:\n",
        "   - The value that appears most frequently in a dataset.\n",
        "   - *Example*: In \\[10, 20, 20, 30\\], the mode is 20.\n",
        "\n",
        "Q12  Define mean, median, and mode ?\n",
        "\n",
        "Certainly! Here’s a clear definition of each:\n",
        "\n",
        " 1. **Mean**:\n",
        "   - The mean, often called the average, is calculated by adding all the values in a dataset and dividing by the total number of values.\n",
        "   - **Example**: For the dataset \\[5, 10, 15\\], the mean is \\((5 + 10 + 15) / 3 = 10\\).\n",
        "\n",
        "2. **Median**:\n",
        "   - The median is the middle value in an ordered dataset. If the dataset has an odd number of values, it’s the one in the center. If even, it’s the average of the two middle values.\n",
        "   - **Example**: For \\[10, 20, 30\\], the median is 20. For \\[10, 20, 30, 40\\], it’s \\((20 + 30) / 2 = 25\\).\n",
        "\n",
        "3. **Mode**:\n",
        "   - The mode is the value that occurs most frequently in a dataset.\n",
        "   - **Example**: In \\[10, 20, 20, 30\\], the mode is 20.\n",
        "\n",
        "\n",
        "Q13  What is the significance of the measure of central tendency ?\n",
        "\n",
        "The measure of central tendency plays a critical role in understanding and interpreting datasets. Its significance lies in the way it provides a single value that summarizes the entire dataset, reflecting the \"center\" or typical value. Here's why it matters:\n",
        "\n",
        " **Significance:**\n",
        "1. **Simplification of Data**:\n",
        "   - In large datasets, measures like mean, median, and mode make it easier to grasp overall trends without analyzing every individual value.\n",
        "\n",
        "2. **Comparison**:\n",
        "   - Central tendency allows for the comparison of different datasets or groups. For example, comparing average income across regions or countries.\n",
        "\n",
        "3. **Decision-Making**:\n",
        "   - Businesses and policymakers rely on measures like mean sales or median incomes to make informed decisions.\n",
        "\n",
        "4. **Identification of Trends**:\n",
        "   - It helps identify where data values cluster, highlighting dominant trends or recurring patterns.\n",
        "\n",
        "5. **Selection of Statistical Methods**:\n",
        "   - Choosing a measure of central tendency guides further analysis, such as determining dispersion (variance, standard deviation).\n",
        "\n",
        "Q14 What is variance, and how is it calculated ?\n",
        "\n",
        "**Variance**:\n",
        "\n",
        "Variance is a statistical measure that represents the degree to which data points in a dataset spread out from the mean (average). It quantifies variability or dispersion, showing how far individual values deviate from the mean.\n",
        "\n",
        "**How is Variance Calculated?**\n",
        "\n",
        "To calculate variance, follow these steps:\n",
        "1. **Find the Mean**:\n",
        "   - Calculate the average of all the data points.\n",
        "\n",
        "2. **Compute Deviations**:\n",
        "   - Subtract the mean from each data point to determine the deviation.\n",
        "\n",
        "3. **Square the Deviations**:\n",
        "   - Square each deviation (to eliminate negative values).\n",
        "\n",
        "4. **Find the Average of Squared Deviations**:\n",
        "   - Add up all the squared deviations and divide by the total number of values (for a population) or by one less than the total (for a sample).\n",
        "\n",
        "**Formula**:\n",
        "- **Population Variance (\\( \\sigma^2 \\))**:\n",
        "  $$ \\sigma^2 = \\frac{\\sum (x_i - \\mu)^2}{N} $$\n",
        "  - \\( x_i \\): Each data point\n",
        "  - \\( \\mu \\): Mean of the population\n",
        "  - \\( N \\): Total number of data points\n",
        "\n",
        "- **Sample Variance (\\( s^2 \\))**:\n",
        "  $$ s^2 = \\frac{\\sum (x_i - \\bar{x})^2}{n - 1} $$\n",
        "  - \\( \\bar{x} \\): Mean of the sample\n",
        "  - \\( n \\): Total number of sample points\n",
        "\n",
        "Q15  What is standard deviation, and why is it important ?\n",
        "\n",
        " **Standard Deviation**:\n",
        "\n",
        "Standard deviation measures the amount of variation or dispersion in a dataset. It indicates how much individual data points deviate from the mean (average) of the dataset. A small standard deviation means the data points are close to the mean, while a large standard deviation indicates they are spread out over a wider range.\n",
        "\n",
        "**Formula**:\n",
        "\n",
        "The standard deviation is the square root of variance:\n",
        "$$ \\sigma = \\sqrt{\\frac{\\sum (x_i - \\mu)^2}{N}} $$\n",
        "- **For Population Standard Deviation (\\( \\sigma \\))**: Use the total population size \\( N \\).\n",
        "- **For Sample Standard Deviation (\\( s \\))**: Use \\( n - 1 \\) instead of \\( N \\) (degrees of freedom).\n",
        "\n",
        " **Steps to Calculate**:\n",
        "\n",
        "1. Find the mean (\\( \\mu \\)).\n",
        "2. Compute the deviation of each data point from the mean.\n",
        "3. Square each deviation.\n",
        "4. Find the average of squared deviations (variance).\n",
        "5. Take the square root of the variance.\n",
        "\n",
        " **Importance of Standard Deviation**:\n",
        "\n",
        "1. **Understanding Data Spread**:\n",
        "   - Provides insight into the consistency of data. For example, in test scores, a small standard deviation suggests most students performed similarly, while a large one shows wide variations in scores.\n",
        "\n",
        "2. **Comparison**:\n",
        "   - Helps compare datasets. For example, two products' reliability can be compared using their standard deviations in performance tests.\n",
        "\n",
        "3. **Risk Assessment**:\n",
        "   - In finance, standard deviation is used to measure investment risk (volatility).\n",
        "\n",
        "4. **Normal Distribution**:\n",
        "   - A crucial feature of bell curves: about 68% of data lies within one standard deviation from the mean, and 95% lies within two.\n",
        "\n",
        "5. **Decision-Making**:\n",
        "   - Offers actionable insights by quantifying variability, useful in quality control, research, and predictive modeling.\n",
        "\n",
        "Q16 Define and explain the term range in statistics ?\n",
        "\n",
        " **Range in Statistics**:\n",
        "\n",
        "The range is a measure of dispersion that represents the difference between the highest and the lowest values in a dataset. It provides a simple way to describe the spread of data by focusing on its extreme points.\n",
        "\n",
        " **Formula**:\n",
        "\n",
        "$$ \\text{Range} = \\text{Maximum Value} - \\text{Minimum Value} $$\n",
        "\n",
        "**Significance**:\n",
        "\n",
        "1. **Understanding Data Spread**:\n",
        "   - The range gives a quick estimate of how spread out the data is. A larger range indicates a wider spread, while a smaller range means the data is more clustered.\n",
        "\n",
        "2. **Ease of Calculation**:\n",
        "   - It’s one of the simplest measures of variability, making it useful for a quick overview of the data.\n",
        "\n",
        "3. **Limitations**:\n",
        "   - **Sensitivity to Outliers**: The range only considers the extreme values, ignoring the rest of the data, so outliers can distort the result.\n",
        "   - **Doesn't Show Distribution**: It doesn’t provide information about the distribution or central tendency of the data.\n",
        "\n",
        "Applications:\n",
        "\n",
        "The range is commonly used in exploratory data analysis, quality control, and comparing datasets to identify variability or consistency.\n",
        "\n",
        "Q17  What is the difference between variance and standard deviation ?\n",
        "\n",
        "Variance and standard deviation are both measures of data dispersion, but they differ in how they represent that variability.\n",
        "\n",
        " **Variance**:\n",
        "\n",
        "- **Definition**: It measures the average squared deviations of each data point from the mean. It's expressed in squared units of the original data.\n",
        "- **Formula**:  \n",
        "  $$ \\sigma^2 = \\frac{\\sum (x_i - \\mu)^2}{N} $$ for a population,  \n",
        "  $$ s^2 = \\frac{\\sum (x_i - \\bar{x})^2}{n - 1} $$ for a sample.\n",
        "- **Purpose**: Useful for understanding the variability of data but can be harder to interpret because it’s in squared units.\n",
        "- **Example**: If the data is in kilograms, variance will be in **kg²**.\n",
        "\n",
        "\n",
        "\n",
        "**Standard Deviation**:\n",
        "\n",
        "- **Definition**: It’s the square root of variance, providing a measure of dispersion in the same units as the original data.\n",
        "- **Formula**:  \n",
        "  $$ \\sigma = \\sqrt{\\sigma^2} $$ (population),  \n",
        "  $$ s = \\sqrt{s^2} $$ (sample).\n",
        "- **Purpose**: Easier to interpret and compare since it reflects the average deviation in original units.\n",
        "- **Example**: If the data is in kilograms, standard deviation will also be in **kg**.\n",
        "\n",
        "\n",
        " **Key Differences**:\n",
        "\n",
        "| **Aspect**           | **Variance**                   | **Standard Deviation**           |\n",
        "|-----------------------|--------------------------------|-----------------------------------|\n",
        "| **Units**            | Squared units (e.g., kg²)     | Same units as the data (e.g., kg) |\n",
        "| **Ease of Interpretation** | Harder to interpret       | Easier to understand             |\n",
        "| **Mathematical Relation** | Basis for standard deviation | Square root of variance          |\n",
        "\n",
        "\n",
        "Q18 What is skewness in a dataset ?\n",
        "\n",
        " **Skewness in a Dataset**:\n",
        "\n",
        "Skewness is a statistical measure that describes the symmetry or asymmetry of a dataset's distribution relative to its mean. It helps identify whether the data is evenly distributed or if it leans more toward one side.\n",
        "\n",
        " **Types of Skewness**:\n",
        "\n",
        "1. **Positive Skew (Right-Skewed)**:\n",
        "   - The tail on the right side of the distribution is longer or more stretched than the left side.\n",
        "   - Most values are concentrated on the lower end, and the mean is greater than the median.\n",
        "   - *Example*: Income distribution in many societies, where a few high-income individuals pull the mean higher.\n",
        "\n",
        "2. **Negative Skew (Left-Skewed)**:\n",
        "\n",
        "   - The tail on the left side is longer or more stretched than the right side.\n",
        "   - Most values are concentrated on the higher end, and the mean is less than the median.\n",
        "   - *Example*: Scores on an easy test, where most students score very high but a few score low.\n",
        "\n",
        "3. **No Skew (Symmetrical Distribution)**:\n",
        "\n",
        "   - The distribution is perfectly symmetrical, meaning the left and right tails are mirror images.\n",
        "   - The mean, median, and mode are equal.\n",
        "   - *Example*: Idealized normal distribution (bell curve).\n",
        "\n",
        " **Significance of Skewness**:\n",
        "\n",
        "- **Data Interpretation**: Helps understand the underlying nature of the dataset and whether assumptions of symmetry hold.\n",
        "- **Choosing Statistical Methods**: Guides whether parametric or non-parametric tests are suitable for analysis.\n",
        "- **Risk Assessment**: In finance, skewness helps evaluate potential risks or returns in investment portfolios.\n",
        "\n",
        "\n",
        "Q19 What does it mean if a dataset is positively or negatively skewed ?\n",
        "\n",
        "When a dataset is **positively or negatively skewed**, it describes how the data is distributed in relation to its mean, median, and mode. Let me explain each:\n",
        "\n",
        "**Positively Skewed (Right-Skewed)**:\n",
        "\n",
        "- **What It Means**:\n",
        "  - The tail on the right side (higher values) is longer or more stretched than the left side.\n",
        "  - Most data points are concentrated at the lower end, but a few extreme high values pull the mean to the right.\n",
        "- **Key Indicators**:\n",
        "  - Mean > Median > Mode.\n",
        "  - Skewness value is **positive**.\n",
        "- **Example**:\n",
        "  - Income distribution: Most people earn a moderate amount, but a small number of individuals earn significantly more, stretching the right tail.\n",
        "\n",
        "**Negatively Skewed (Left-Skewed)**:\n",
        "\n",
        "- **What It Means**:\n",
        "  - The tail on the left side (lower values) is longer or more stretched than the right side.\n",
        "  - Most data points are concentrated at the higher end, but a few extreme low values pull the mean to the left.\n",
        "- **Key Indicators**:\n",
        "  - Mean < Median < Mode.\n",
        "  - Skewness value is **negative**.\n",
        "- **Example**:\n",
        "  - Exam scores on an easy test: Most students score very high, but a few score very low, stretching the left tail.\n",
        "\n",
        "\n",
        "Q20 Define and explain kurtosis ?\n",
        " **Kurtosis**:\n",
        "\n",
        "Kurtosis is a statistical measure that describes the shape of a dataset's distribution, specifically the \"tailedness\" or the presence of outliers. It quantifies whether the data points have heavier or lighter tails compared to a normal distribution.\n",
        "\n",
        " **Types of Kurtosis**:\n",
        "\n",
        "1. **Mesokurtic**:\n",
        "   - Distributions with kurtosis similar to that of a normal distribution (kurtosis = 3, excess kurtosis = 0).\n",
        "   - Tails are of moderate thickness, with no significant outliers.\n",
        "   - *Example*: Normal distribution.\n",
        "\n",
        "2. **Leptokurtic**:\n",
        "   - Distributions with kurtosis greater than 3 (excess kurtosis > 0).\n",
        "   - Tails are thicker, indicating the presence of more extreme outliers.\n",
        "   - *Example*: Income data with many extremely high earners.\n",
        "\n",
        "3. **Platykurtic**:\n",
        "   - Distributions with kurtosis less than 3 (excess kurtosis < 0).\n",
        "   - Tails are thinner, meaning fewer extreme outliers.\n",
        "   - *Example*: Uniform distribution.\n",
        "\n",
        "### **Formula for Kurtosis**:\n",
        "Kurtosis is computed using:\n",
        "$$ K = \\frac{\\sum (x_i - \\mu)^4}{N \\cdot \\sigma^4} $$\n",
        "Where:\n",
        "- \\( x_i \\): Each data point\n",
        "- \\( \\mu \\): Mean of the data\n",
        "- \\( \\sigma^2 \\): Variance\n",
        "- \\( N \\): Number of data points\n",
        "\n",
        "Q21 What is the purpose of covariance ?\n",
        "\n",
        " **Purpose of Covariance**:\n",
        "\n",
        "Covariance is a statistical measure that quantifies the relationship between two variables. Specifically, it shows whether an increase in one variable corresponds to an increase or decrease in another. The primary purpose of covariance is to understand the directional relationship between variables.\n",
        "\n",
        " **Key Objectives**:\n",
        "\n",
        "1. **Identify Relationships**:\n",
        "\n",
        "   - Determines whether two variables move together (positive covariance) or in opposite directions (negative covariance).\n",
        "\n",
        "2. **Foundation for Further Analysis**:\n",
        "\n",
        "   - Covariance is a building block for calculating the **correlation coefficient**, which standardizes the strength and direction of relationships.\n",
        "\n",
        "3. **Model Development**:\n",
        "\n",
        "   - In fields like finance, covariance helps assess how assets interact, aiding portfolio management and diversification strategies.\n",
        "\n",
        "Q22  What does correlation measure in statistics ?\n",
        "\n",
        "**Correlation in Statistics**:\n",
        "\n",
        "Correlation measures the strength and direction of a linear relationship between two variables. It quantifies how closely the changes in one variable are associated with changes in another.\n",
        "\n",
        " **Key Points**:\n",
        "\n",
        "1. **Direction**:\n",
        "   - **Positive Correlation**: As one variable increases, the other also increases. *Example*: Height and weight.\n",
        "   - **Negative Correlation**: As one variable increases, the other decreases. *Example*: Speed and travel time.\n",
        "   - **No Correlation**: No consistent relationship between the variables. *Example*: Shoe size and IQ.\n",
        "\n",
        "2. **Strength**:\n",
        "   - Measured using the **correlation coefficient** (\\(r\\)), which ranges from **-1 to +1**:\n",
        "     - **+1**: Perfect positive correlation.\n",
        "     - **-1**: Perfect negative correlation.\n",
        "     - **0**: No correlation.\n",
        "\n",
        "3. **Formula**:\n",
        "   $$ r = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\cdot \\sigma_Y} $$\n",
        "   - Where \\( \\text{Cov}(X, Y) \\) is the covariance, and \\( \\sigma_X \\) and \\( \\sigma_Y \\) are the standard deviations of \\( X \\) and \\( Y \\).\n",
        "\n",
        "Q23 What is the difference between covariance and correlation ?\n",
        "\n",
        "Covariance and correlation are both measures used to assess the relationship between two variables, but they differ in interpretation, scale, and purpose.\n",
        "\n",
        " **Key Differences**:\n",
        "\n",
        "| **Aspect**               | **Covariance**                           | **Correlation**                     |\n",
        "|--------------------------|------------------------------------------|--------------------------------------|\n",
        "| **Definition**           | Quantifies how two variables change together. | Measures the strength and direction of a linear relationship. |\n",
        "| **Scale**                | Values are not standardized; depend on the units of the variables. | Standardized between **-1** and **+1**. |\n",
        "| **Interpretation**        | Positive covariance: Variables increase/decrease together.<br>Negative covariance: One variable increases while the other decreases. | Positive correlation: Strong positive relationship.<br>Negative correlation: Strong negative relationship.<br>Zero correlation: No linear relationship. |\n",
        "| **Units**                | Based on the product of the units of both variables. | Unitless; easy to compare across datasets. |\n",
        "| **Formula**              | $$ \\text{Cov}(X, Y) = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{N} $$ | $$ r = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\cdot \\sigma_Y} $$ |\n",
        "| **Purpose**              | Highlights the directional relationship between variables. | Quantifies both the strength and direction of the relationship. |\n",
        "\n",
        "Q24  What are some real-world applications of statistics?\n",
        "\n",
        "Statistics is a versatile and essential tool in countless real-world applications. Here are some examples where statistics plays a key role:\n",
        "\n",
        " **1. Healthcare and Medicine**:\n",
        "   - **Clinical Trials**: Used to test the safety and effectiveness of new treatments or medications.\n",
        "   - **Epidemiology**: Tracks and predicts the spread of diseases, such as during COVID-19.\n",
        "   - **Patient Care**: Hospitals analyze patient data to improve diagnoses and treatments.\n",
        "\n",
        "**2. Business and Economics**:\n",
        "   - **Market Research**: Companies analyze consumer preferences and market trends to develop strategies.\n",
        "   - **Quality Control**: Ensures product consistency through statistical sampling methods.\n",
        "   - **Risk Analysis**: Evaluates financial risks, aiding in decision-making for investments and loans.\n",
        "\n",
        "**3. Education**:\n",
        "   - **Standardized Testing**: Measures student performance and compares results across populations.\n",
        "   - **Curriculum Development**: Uses data on student learning outcomes to optimize teaching methods.\n",
        "\n",
        " **4. Sports and Entertainment**:\n",
        "   - **Performance Analysis**: Tracks player statistics to improve strategies and training.\n",
        "   - **Audience Analytics**: Assesses viewer preferences and trends for content optimization.\n",
        "\n",
        " **5. Environment and Ecology**:\n",
        "   - **Climate Studies**: Analyzes weather patterns and climate changes.\n",
        "   - **Wildlife Conservation**: Tracks animal populations to guide conservation efforts.\n",
        "\n",
        " **6. Government and Policy-Making**:\n",
        "   - **Census Data**: Shapes policies by understanding population demographics.\n",
        "   - **Crime Statistics**: Helps allocate resources for law enforcement and safety programs.\n",
        "\n",
        "**7. Technology and Artificial Intelligence**:\n",
        "   - **Machine Learning**: Relies on statistical models to train algorithms.\n",
        "   - **Data Science**: Extracts insights from large datasets for innovation and efficiency.\n",
        "\n"
      ],
      "metadata": {
        "id": "7C_uhHUS-Bhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "...\n",
        "***Practial Questions ***\n",
        "#Q1  How do you calculate the mean, median, and mode of a dataset ?\n",
        "\n",
        "from statistics import mean, median, mode\n",
        "\n",
        "# Example dataset\n",
        "data = [1, 2, 3, 3, 4, 5, 5, 5, 6]\n",
        "\n",
        "# Calculate mean, median, and mode\n",
        "mean_value = mean(data)\n",
        "median_value = median(data)\n",
        "\n",
        "# Mode calculation may throw an exception if the dataset has no mode\n",
        "try:\n",
        "    mode_value = mode(data)\n",
        "except:\n",
        "    mode_value = \"No mode\"\n",
        "\n",
        "# Print results\n",
        "print(\"Mean:\", mean_value)\n",
        "print(\"Median:\", median_value)\n",
        "print(\"Mode:\", mode_value)\n",
        "...\n",
        "#Q2 Write a Python program to compute the variance and standard deviation of a dataset ?\n",
        "\n",
        "from statistics import variance, stdev\n",
        "\n",
        "# Example dataset\n",
        "data = [2, 4, 6, 8, 10]\n",
        "\n",
        "# Calculate variance and standard deviation\n",
        "variance_value = variance(data)\n",
        "standard_deviation_value = stdev(data)\n",
        "\n",
        "# Display the results\n",
        "print(\"Variance:\", variance_value)\n",
        "print(\"Standard Deviation:\", standard_deviation_value)\n",
        "...\n",
        "#Q3 Create a dataset and classify it into nominal, ordinal, interval, and ratio types ?\n",
        "\n",
        "# Define the dataset as a dictionary\n",
        "dataset = {\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"Daisy\"],\n",
        "    \"Category\": [\"Engineer\", \"Teacher\", \"Doctor\", \"Nurse\"],  # Nominal\n",
        "    \"Rating\": [\"Excellent\", \"Good\", \"Fair\", \"Poor\"],         # Ordinal\n",
        "    \"Temperature (°C)\": [25, 30, 28, 24],                    # Interval\n",
        "    \"Income (USD)\": [50000, 40000, 60000, 35000]             # Ratio\n",
        "}\n",
        "\n",
        "# Classify the variables\n",
        "classification = {\n",
        "    \"Nominal\": [\"Category\"],  # Represents labels without order\n",
        "    \"Ordinal\": [\"Rating\"],    # Represents ordered categories\n",
        "    \"Interval\": [\"Temperature (°C)\"],  # Ordered with no true zero\n",
        "    \"Ratio\": [\"Income (USD)\"]          # Ordered with true zero\n",
        "}\n",
        "\n",
        "# Display the dataset and classifications\n",
        "print(\"Dataset:\")\n",
        "for key, values in dataset.items():\n",
        "    print(f\"{key}: {values}\")\n",
        "\n",
        "print(\"\\nClassification:\")\n",
        "for key, values in classification.items():\n",
        "    print(f\"{key}: {values}\")\n",
        "...\n",
        "#Q4 Implement sampling techniques like random sampling and stratified sampling ?\n",
        "\n",
        "import random\n",
        "\n",
        "# Dataset\n",
        "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "\n",
        "# Randomly selecting 5 samples from the dataset\n",
        "random_samples = random.sample(data, 5)\n",
        "\n",
        "print(\"Random Samples:\", random_samples)\n",
        "...\n",
        "#Q5  Write a Python function to calculate the range of a dataset ?\n",
        "\n",
        "def calculate_range(data):\n",
        "    \"\"\"\n",
        "    Function to calculate the range of a dataset.\n",
        "\n",
        "    Parameters:\n",
        "        data (list): A list of numerical values.\n",
        "\n",
        "    Returns:\n",
        "        int/float: The range of the dataset.\n",
        "    \"\"\"\n",
        "    if not data:\n",
        "        return \"Dataset is empty. Please provide valid data.\"\n",
        "\n",
        "    # Calculate the range\n",
        "    data_range = max(data) - min(data)\n",
        "    return data_range\n",
        "\n",
        "# Example usage\n",
        "dataset = [10, 20, 30, 40, 50]\n",
        "result = calculate_range(dataset)\n",
        "print(\"Range of the dataset:\", result)\n",
        "...\n",
        "#Q6 Create a dataset and plot its histogram to visualize skewness ?\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Create a dataset\n",
        "# Positively skewed dataset (e.g., income data with a few high outliers)\n",
        "data = [10, 15, 15, 20, 25, 25, 25, 30, 30, 35, 40, 45, 50, 100, 200]\n",
        "\n",
        "# Plot a histogram\n",
        "plt.hist(data, bins=10, color='blue', edgecolor='black', alpha=0.7)\n",
        "plt.title('Histogram of Dataset')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Add grid for better readability\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "...\n",
        "#Q7 Calculate skewness and kurtosis of a dataset using Python libraries ?\n",
        "\n",
        "import pandas as pd\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Create a dataset\n",
        "data = [2, 4, 6, 8, 10, 20, 30, 40, 50, 100]  # Example dataset\n",
        "\n",
        "# Calculate skewness and kurtosis\n",
        "data_skewness = skew(data)\n",
        "data_kurtosis = kurtosis(data)\n",
        "\n",
        "# Display results\n",
        "print(\"Skewness of the dataset:\", data_skewness)\n",
        "print(\"Kurtosis of the dataset:\", data_kurtosis)\n",
        "...\n",
        "#Q8 Generate a dataset and demonstrate positive and negative skewness ?\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import skew\n",
        "\n",
        "# Generate positively skewed data (e.g., exponential distribution)\n",
        "positive_skew_data = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Generate negatively skewed data (by inverting exponential distribution)\n",
        "negative_skew_data = -1 * np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Calculate skewness\n",
        "positive_skewness = skew(positive_skew_data)\n",
        "negative_skewness = skew(negative_skew_data)\n",
        "\n",
        "# Plot histograms\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Positive skew\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(positive_skew_data, bins=20, color='blue', edgecolor='black', alpha=0.7)\n",
        "plt.title(f'Positively Skewed Data (Skewness: {positive_skewness:.2f})')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Negative skew\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(negative_skew_data, bins=20, color='green', edgecolor='black', alpha=0.7)\n",
        "plt.title(f'Negatively Skewed Data (Skewness: {negative_skewness:.2f})')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Display plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "...\n",
        "#Q9 Write a Python script to calculate covariance between two datasets ?\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def calculate_covariance(data1, data2):\n",
        "    \"\"\"\n",
        "    Function to calculate the covariance between two datasets.\n",
        "\n",
        "    Parameters:\n",
        "        data1 (list or array): First dataset\n",
        "        data2 (list or array): Second dataset\n",
        "\n",
        "    Returns:\n",
        "        float: Covariance between the two datasets\n",
        "    \"\"\"\n",
        "    if len(data1) != len(data2):\n",
        "        return \"Datasets must have the same length.\"\n",
        "\n",
        "    # Convert to NumPy arrays for easy calculation\n",
        "    data1 = np.array(data1)\n",
        "    data2 = np.array(data2)\n",
        "\n",
        "    # Calculate the mean of each dataset\n",
        "    mean1 = np.mean(data1)\n",
        "    mean2 = np.mean(data2)\n",
        "\n",
        "    # Compute covariance\n",
        "    covariance = np.mean((data1 - mean1) * (data2 - mean2))\n",
        "    return covariance\n",
        "\n",
        "# Example datasets\n",
        "dataset1 = [1, 2, 3, 4, 5]\n",
        "dataset2 = [5, 10, 15, 20, 25]\n",
        "\n",
        "# Calculate covariance\n",
        "covariance_result = calculate_covariance(dataset1, dataset2)\n",
        "\n",
        "# Print the result\n",
        "print(\"Covariance between the two datasets:\", covariance_result)\n",
        "...\n",
        "#Q10 Write a Python script to calculate the correlation coefficient between two datasets ?\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def calculate_correlation(data1, data2):\n",
        "    \"\"\"\n",
        "    Function to calculate the correlation coefficient between two datasets.\n",
        "\n",
        "    Parameters:\n",
        "        data1 (list or array): First dataset\n",
        "        data2 (list or array): Second dataset\n",
        "\n",
        "    Returns:\n",
        "        float: Correlation coefficient\n",
        "    \"\"\"\n",
        "    if len(data1) != len(data2):\n",
        "        return \"Datasets must have the same length.\"\n",
        "\n",
        "    # Convert to NumPy arrays\n",
        "    data1 = np.array(data1)\n",
        "    data2 = np.array(data2)\n",
        "\n",
        "    # Compute correlation coefficient\n",
        "    correlation_matrix = np.corrcoef(data1, data2)\n",
        "    correlation_coefficient = correlation_matrix[0, 1]  # Extract the correlation coefficient\n",
        "    return correlation_coefficient\n",
        "\n",
        "# Example datasets\n",
        "dataset1 = [1, 2, 3, 4, 5]\n",
        "dataset2 = [5, 10, 15, 20, 25]\n",
        "\n",
        "# Calculate correlation coefficient\n",
        "correlation_result = calculate_correlation(dataset1, dataset2)\n",
        "\n",
        "# Print the result\n",
        "print(\"Correlation Coefficient:\", correlation_result)\n",
        "...\n",
        "#Q11 Create a scatter plot to visualize the relationship between two variables ?\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example datasets\n",
        "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # Independent variable\n",
        "y = [2, 4, 5, 7, 10, 12, 14, 15, 18, 20]  # Dependent variable\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.scatter(x, y, color='blue', edgecolor='black', alpha=0.8)\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Scatter Plot of Two Variables')\n",
        "plt.xlabel('X (Independent Variable)')\n",
        "plt.ylabel('Y (Dependent Variable)')\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "...\n",
        "#Q11  Implement and compare simple random sampling and systematic sampling ?\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Example dataset\n",
        "data = [i for i in range(1, 101)]  # Dataset with 100 elements (1 to 100)\n",
        "\n",
        "# Simple Random Sampling\n",
        "def simple_random_sampling(data, sample_size):\n",
        "    return random.sample(data, sample_size)\n",
        "\n",
        "# Systematic Sampling\n",
        "def systematic_sampling(data, sample_size):\n",
        "    step = len(data) // sample_size  # Calculate the step size\n",
        "    return [data[i] for i in range(0, len(data), step)][:sample_size]\n",
        "\n",
        "# Define sample size\n",
        "sample_size = 10\n",
        "\n",
        "# Perform sampling\n",
        "simple_random_sample = simple_random_sampling(data, sample_size)\n",
        "systematic_sample = systematic_sampling(data, sample_size)\n",
        "\n",
        "# Display results\n",
        "print(\"Original Dataset:\", data)\n",
        "print(\"Simple Random Sample:\", simple_random_sample)\n",
        "print(\"Systematic Sample:\", systematic_sample)\n",
        "...\n",
        "#Q12 Calculate the mean, median, and mode of grouped data ?\n",
        "\n",
        "# Function to calculate Mean, Median, and Mode for grouped data\n",
        "def calculate_grouped_data_metrics(frequencies, midpoints):\n",
        "    \"\"\"\n",
        "    Calculates the mean, median, and mode of grouped data.\n",
        "\n",
        "    Parameters:\n",
        "        frequencies (list): Frequency of each group.\n",
        "        midpoints (list): Midpoints of each group (representing group intervals).\n",
        "\n",
        "    Returns:\n",
        "        dict: Mean, Median, and Mode as a dictionary.\n",
        "    \"\"\"\n",
        "    # Total frequency\n",
        "    total_frequency = sum(frequencies)\n",
        "\n",
        "    # Mean calculation\n",
        "    mean = sum([f * m for f, m in zip(frequencies, midpoints)]) / total_frequency\n",
        "\n",
        "    # Median calculation\n",
        "    cumulative_frequencies = [sum(frequencies[:i + 1]) for i in range(len(frequencies))]\n",
        "    median_index = next(i for i, cf in enumerate(cumulative_frequencies) if cf > total_frequency / 2)\n",
        "    median_class_midpoint = midpoints[median_index]\n",
        "\n",
        "    # Mode calculation\n",
        "    mode_index = frequencies.index(max(frequencies))\n",
        "    mode = midpoints[mode_index]\n",
        "\n",
        "    # Results\n",
        "    return {\"Mean\": mean, \"Median\": median_class_midpoint, \"Mode\": mode}\n",
        "\n",
        "\n",
        "# Grouped data example (Midpoints and Frequencies of intervals)\n",
        "grouped_data_midpoints = [5, 15, 25, 35, 45]  # Midpoints of intervals\n",
        "grouped_data_frequencies = [4, 8, 10, 5, 3]   # Frequencies of intervals\n",
        "\n",
        "# Calculate metrics\n",
        "results = calculate_grouped_data_metrics(grouped_data_frequencies, grouped_data_midpoints)\n",
        "\n",
        "# Print the results\n",
        "print(\"Grouped Data Metrics:\")\n",
        "for key, value in results.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "\n",
        "...\n",
        "#Q14 Simulate data using Python and calculate its central tendency and dispersion. ?\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import mode\n",
        "from statistics import variance, stdev\n",
        "\n",
        "# Simulate data: Generate 100 random numbers from a normal distribution\n",
        "np.random.seed(42)  # For reproducibility\n",
        "data = np.random.normal(loc=50, scale=10, size=100)  # Mean=50, StdDev=10\n",
        "\n",
        "# Calculate central tendency\n",
        "mean_value = np.mean(data)  # Mean\n",
        "median_value = np.median(data)  # Median\n",
        "mode_value = mode(data, keepdims=False).mode  # Mode\n",
        "\n",
        "# Calculate dispersion\n",
        "variance_value = variance(data)  # Variance\n",
        "std_dev_value = stdev(data)  # Standard Deviation\n",
        "range_value = max(data) - min(data)  # Range\n",
        "\n",
        "# Display results\n",
        "print(\"Simulated Data:\", data)\n",
        "print(\"\\n--- Central Tendency ---\")\n",
        "print(f\"Mean: {mean_value:.2f}\")\n",
        "print(f\"Median: {median_value:.2f}\")\n",
        "print(f\"Mode: {mode_value:.2f}\")\n",
        "\n",
        "print(\"\\n--- Dispersion ---\")\n",
        "print(f\"Variance: {variance_value:.2f}\")\n",
        "print(f\"Standard Deviation: {std_dev_value:.2f}\")\n",
        "print(f\"Range: {range_value:.2f}\")\n",
        "...\n",
        "#Q15  Use NumPy or pandas to summarize a dataset’s descriptive statistics ?\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample dataset\n",
        "data = {\n",
        "    \"Age\": [22, 25, 29, 35, 42, 55, 63, 36, 47, 50],\n",
        "    \"Income\": [25000, 30000, 40000, 45000, 50000, 65000, 70000, 48000, 52000, 60000],\n",
        "    \"Score\": [85, 90, 88, 75, 92, 77, 85, 84, 79, 91]\n",
        "}\n",
        "\n",
        "# Convert the dataset to a pandas DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Generate descriptive statistics\n",
        "summary = df.describe()\n",
        "\n",
        "# Display the summary\n",
        "print(\"Descriptive Statistics:\\n\", summary)\n",
        "\n",
        "...\n",
        "#Q16 Plot a boxplot to understand the spread and identify outliers ?\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate example data\n",
        "np.random.seed(42)  # For reproducibility\n",
        "data = np.random.normal(loc=50, scale=10, size=200)  # Dataset with mean=50, stddev=10\n",
        "\n",
        "# Add a few outliers to the data\n",
        "data = np.append(data, [100, 105, 110])\n",
        "\n",
        "# Create the boxplot\n",
        "plt.boxplot(data, vert=False, patch_artist=True, boxprops=dict(facecolor=\"lightblue\"))\n",
        "\n",
        "# Customize the plot\n",
        "plt.title(\"Boxplot to Understand Spread and Identify Outliers\")\n",
        "plt.xlabel(\"Values\")\n",
        "plt.grid(axis=\"x\", alpha=0.5)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "...\n",
        "#Q17  Calculate the interquartile range (IQR) of a dataset ?\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def calculate_iqr(data):\n",
        "    \"\"\"\n",
        "    Function to calculate the Interquartile Range (IQR) of a dataset.\n",
        "\n",
        "    Parameters:\n",
        "        data (list or array): A list of numerical values.\n",
        "\n",
        "    Returns:\n",
        "        float: The IQR of the dataset.\n",
        "    \"\"\"\n",
        "    # Convert the dataset to a NumPy array for easy calculation\n",
        "    data = np.array(data)\n",
        "\n",
        "    # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
        "    Q1 = np.percentile(data, 25)\n",
        "    Q3 = np.percentile(data, 75)\n",
        "\n",
        "    # Calculate IQR\n",
        "    IQR = Q3 - Q1\n",
        "    return IQR\n",
        "\n",
        "# Example dataset\n",
        "dataset = [10, 15, 14, 20, 25, 22, 28, 30, 35, 40, 45, 50]\n",
        "\n",
        "# Calculate IQR\n",
        "iqr_result = calculate_iqr(dataset)\n",
        "\n",
        "# Print the result\n",
        "print(\"Interquartile Range (IQR):\", iqr_result)\n",
        "...\n",
        "#Q18 Implement Z-score normalization and explain its significance ?\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def z_score_normalization(data):\n",
        "    \"\"\"\n",
        "    Function to apply Z-score normalization to a dataset.\n",
        "\n",
        "    Parameters:\n",
        "        data (list or array): A list of numerical values.\n",
        "\n",
        "    Returns:\n",
        "        list: Normalized dataset using Z-score.\n",
        "    \"\"\"\n",
        "    # Convert to NumPy array\n",
        "    data = np.array(data)\n",
        "\n",
        "    # Calculate the mean and standard deviation\n",
        "    mean = np.mean(data)\n",
        "    std_dev = np.std(data)\n",
        "\n",
        "    # Apply Z-score normalization\n",
        "    z_scores = (data - mean) / std_dev\n",
        "    return z_scores\n",
        "\n",
        "# Example dataset\n",
        "data = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "\n",
        "# Perform Z-score normalization\n",
        "normalized_data = z_score_normalization(data)\n",
        "\n",
        "# Display results\n",
        "print(\"Original Data:\", data)\n",
        "print(\"Z-score Normalized Data:\", normalized_data)\n",
        "...\n",
        "#Q19 Compare two datasets using their standard deviations ?\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def compare_standard_deviations(data1, data2):\n",
        "    \"\"\"\n",
        "    Function to calculate and compare the standard deviations of two datasets.\n",
        "\n",
        "    Parameters:\n",
        "        data1 (list or array): First dataset\n",
        "        data2 (list or array): Second dataset\n",
        "\n",
        "    Returns:\n",
        "        dict: Standard deviations and their comparison\n",
        "    \"\"\"\n",
        "    # Convert datasets to NumPy arrays\n",
        "    data1 = np.array(data1)\n",
        "    data2 = np.array(data2)\n",
        "\n",
        "    # Calculate standard deviations\n",
        "    std_dev1 = np.std(data1)\n",
        "    std_dev2 = np.std(data2)\n",
        "\n",
        "    # Compare standard deviations\n",
        "    comparison = \"Dataset 1 has higher variability\" if std_dev1 > std_dev2 else \\\n",
        "                 \"Dataset 2 has higher variability\" if std_dev2 > std_dev1 else \\\n",
        "                 \"Both datasets have the same variability\"\n",
        "\n",
        "    # Return results\n",
        "    return {\"Standard Deviation of Dataset 1\": std_dev1,\n",
        "            \"Standard Deviation of Dataset 2\": std_dev2,\n",
        "            \"Comparison\": comparison}\n",
        "\n",
        "# Example datasets\n",
        "dataset1 = [10, 20, 30, 40, 50]\n",
        "dataset2 = [15, 25, 35, 45, 55]\n",
        "\n",
        "# Compare standard deviations\n",
        "results = compare_standard_deviations(dataset1, dataset2)\n",
        "\n",
        "# Print results\n",
        "print(\"Comparison Results:\")\n",
        "for key, value in results.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "...\n",
        "#Q20 Write a Python program to visualize covariance using a heatmap ?\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a sample dataset\n",
        "data = {\n",
        "    \"Variable A\": [10, 20, 30, 40, 50],\n",
        "    \"Variable B\": [15, 25, 35, 45, 55],\n",
        "    \"Variable C\": [50, 40, 30, 20, 10]\n",
        "}\n",
        "\n",
        "# Convert the dataset to a pandas DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the covariance matrix\n",
        "cov_matrix = df.cov()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cov_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", cbar=True)\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Covariance Matrix Heatmap')\n",
        "plt.show()\n",
        "...\n",
        "#Q21 Use seaborn to create a correlation matrix for a dataset ?\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a sample dataset\n",
        "data = {\n",
        "    \"Age\": [22, 25, 29, 35, 42, 55, 63, 36, 47, 50],\n",
        "    \"Income\": [25000, 30000, 40000, 45000, 50000, 65000, 70000, 48000, 52000, 60000],\n",
        "    \"Score\": [85, 90, 88, 75, 92, 77, 85, 84, 79, 91]\n",
        "}\n",
        "\n",
        "# Convert the dataset into a pandas DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", cbar=True)\n",
        "\n",
        "# Customize the plot\n",
        "plt.title(\"Correlation Matrix Heatmap\")\n",
        "plt.show()\n",
        "...\n",
        "\n",
        "#Q22 Generate a dataset and implement both variance and standard deviation computations ?\n",
        "\n",
        "import numpy as np\n",
        "from statistics import variance, stdev\n",
        "\n",
        "# Generate a dataset: Random integers between 1 and 100\n",
        "np.random.seed(42)\n",
        "data = np.random.randint(1, 101, size=20)\n",
        "\n",
        "# Calculate variance and standard deviation\n",
        "variance_value = variance(data)\n",
        "std_dev_value = stdev(data)\n",
        "# Display results\n",
        "print(\"Generated Dataset:\", data)\n",
        "print(\"\\n--- Computations ---\")\n",
        "print(f\"Variance: {variance_value:.2f}\")\n",
        "print(f\"Standard Deviation: {std_dev_value:.2f}\")\n",
        "...\n",
        "#Q23 Visualize skewness and kurtosis using Python libraries like matplotlib or seaborn ?\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Generate example data\n",
        "np.random.seed(42)\n",
        "data = np.random.normal(loc=50, scale=10, size=500)\n",
        "\n",
        "# Add some skewness (positively skewed)\n",
        "skewed_data = np.append(data, [100, 110, 115])\n",
        "\n",
        "# Calculate skewness and kurtosis\n",
        "data_skewness = skew(skewed_data)\n",
        "data_kurtosis = kurtosis(skewed_data)\n",
        "\n",
        "# Visualization using histograms\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Histogram with Matplotlib\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(skewed_data, bins=20, color='blue', edgecolor='black', alpha=0.7)\n",
        "plt.title(f\"Histogram (Skewness: {data_skewness:.2f}, Kurtosis: {data_kurtosis:.2f})\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(axis='y')\n",
        "\n",
        "# Histogram with Seaborn\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(skewed_data, kde=True, color='green')\n",
        "plt.title(f\"Seaborn Histogram (Skewness: {data_skewness:.2f}, Kurtosis: {data_kurtosis:.2f})\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "...\n",
        "#Q24 Implement the Pearson and Spearman correlation coefficients for a dataset. ?\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "# Create example datasets\n",
        "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "y = [2, 4, 5, 8, 10, 12, 14, 15, 18, 20]\n",
        "\n",
        "# Calculate Pearson correlation coefficient\n",
        "pearson_corr, pearson_p_value = pearsonr(x, y)\n",
        "\n",
        "# Calculate Spearman correlation coefficient\n",
        "spearman_corr, spearman_p_value = spearmanr(x, y)\n",
        "\n",
        "# Display results\n",
        "print(\"--- Correlation Coefficients ---\")\n",
        "print(f\"Pearson Correlation: {pearson_corr:.2f} (p-value: {pearson_p_value:.2e})\")\n",
        "print(f\"Spearman Correlation: {spearman_corr:.2f} (p-value: {spearman_p_value:.2e})\")\n",
        "..."
      ],
      "metadata": {
        "id": "E1dZLXyNF4l1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}